{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This Notebook is specifically to extract features from those chunks which we have made in other notebook"
      ],
      "metadata": {
        "id": "nMdiHxtb4eae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notenook should be run for the number of chunks you have made in parallel to speed up the process.\n",
        "\n",
        "# For each chunk you have to change value of the chunk number only in the last cell of this notebook"
      ],
      "metadata": {
        "id": "2lZAGS4_48ay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLgF-9_-NnEG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(15)\n",
        "import json\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make sure to mount your drive\n",
        "You must have all the chunks of uri's from which you want to extract features from"
      ],
      "metadata": {
        "id": "n-TubEXs4ta2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d8l5l-OSfvM",
        "outputId": "766738dc-7cb4-47e5-eca8-bbabadb4bff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spotipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkkQOm4INp-F",
        "outputId": "cd4553b5-9773-4914-c041-1c354760a50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spotipy\n",
            "  Downloading spotipy-2.20.0-py3-none-any.whl (27 kB)\n",
            "Collecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.3\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 40.2 MB/s \n",
            "\u001b[?25hCollecting requests>=2.25.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spotipy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.3->spotipy) (4.1.1)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.3->spotipy) (4.0.2)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.3->spotipy) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.3->spotipy) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.3->spotipy) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.3->spotipy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.3->spotipy) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->spotipy) (2.1.1)\n",
            "Installing collected packages: urllib3, deprecated, requests, redis, spotipy\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed deprecated-1.2.13 redis-4.3.4 requests-2.28.1 spotipy-2.20.0 urllib3-1.26.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spotipy\n",
        "import spotipy.oauth2 as oauth2\n",
        "from spotipy.oauth2 import SpotifyOAuth\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import time"
      ],
      "metadata": {
        "id": "1lONPh8xNv8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_track_features(track_id):\n",
        "  audio = sp.audio_features(track_id)\n",
        "  track = sp.track(track_id)\n",
        "\n",
        "  # Album Features\n",
        "  release_date = track['album']['release_date']\n",
        "  album_total_tracks = track['album']['total_tracks']\n",
        "  popularity = track['popularity']\n",
        "\n",
        "  # Audio Features\n",
        "  uri = audio[0]['id']\n",
        "  danceability = audio[0]['danceability']\n",
        "  energy = audio[0]['energy']\n",
        "  key = audio[0]['key']\n",
        "  loudness = audio[0]['loudness']\n",
        "  mode = audio[0]['mode']\n",
        "  speechiness = audio[0]['speechiness']\n",
        "  acousticness = audio[0]['acousticness']\n",
        "  instrumentalness = audio[0]['instrumentalness']\n",
        "  liveness = audio[0]['liveness']\n",
        "  valence = audio[0]['valence']\n",
        "  tempo = audio[0]['tempo']\n",
        "  time_signature = audio[0]['time_signature']\n",
        "\n",
        "  track_data = [uri , release_date , album_total_tracks , popularity , danceability , energy , key , loudness , mode , speechiness , acousticness , instrumentalness , liveness , valence , tempo , time_signature]\n",
        "  return track_data"
      ],
      "metadata": {
        "id": "VrIfFXuINwdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Extract_Features(dataframe_chunk,chunk_no): \n",
        "  i=0    # counter variable \n",
        "  j=0   # variable to print the progress\n",
        "  track_features=[]   # list to append the features recieved from sporify API\n",
        "  for uri in dataframe_chunk:\n",
        "    if i<900:   # if i < 900 (you can choose any counter number) this if condition will send 900 request for features to spotify one by one for each track uri\n",
        "      \n",
        "      if uri == '656TZlNdVe90zHvmebFt9U' or uri == '5GiU7GOYjDH2yp7fMf9w9j' or uri == '2ZF3gpgGPjOfi1yTWGX6Bm' or uri == '2odGdanrUsgu0d2i2Q5XoT' or uri == '6tf7ENqpF89Xox3xyNPGMv' or uri == '0fJ6UuZ7onqcldGr8HT5QV' or uri == '0Jb7g80rInlj3fa6W65Bp2':\n",
        "        # this confition is to avoid getting error 404 since these uri's are not available anymore on spotify API\n",
        "        track_features.append([uri if i==0 else np.nan for i in range(16)]) # for these uri's we are appending NaN values and will deal with these sample later\n",
        "\n",
        "      else: # if other uri's (which we can extract features from spotify API)\n",
        "        track_features.append(get_track_features(uri)) # storing recieved features from spotify API to later use them to concatenate in out main data frame\n",
        "        j+=1 # increment j for every succesfully recieved features to keep the track of how many samples are done to later print it\n",
        "\n",
        "    else: # if i is greater than 900, it means that we now have made enough request consequtively to API, so we will sleep for some time and reset the counter to 0\n",
        "      time.sleep(0.1)\n",
        "      print(j)\n",
        "      i=0\n",
        "    i+=1 # incrementing i for every uri in dataset\n",
        "  uri_length = len(track_features)\n",
        "  print(\"Number of total uri's we have completed extracting features: \", uri_length)\n",
        "  track_features_df = pd.DataFrame(track_features, columns=['uri', 'release_date', 'album_total_tracks', 'popularity','danceability','energy','key','loudness', 'mode', 'speechiness','acousticness','instrumentalness','liveness','valence','tempo','time_signature'])\n",
        "  track_features_df.to_csv(\"features(\"+chunk_no+\").csv\")\n",
        "  shutil.copy(\"features(\"+chunk_no+\").csv\",\"/content/drive/MyDrive/Datasets\")   # saving the dataframe chunk to drive"
      ],
      "metadata": {
        "id": "rt01RE5KN2Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the credentials for while extracting features for each chunk may improve the speed of the process\n",
        "It worked for me though :)"
      ],
      "metadata": {
        "id": "3k3Wva9h5Tpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth_manager = SpotifyClientCredentials(client_id='6b92235a9748428bad27a3daf3df595a',\n",
        "                                        client_secret='9b16b438472948a89671b1764825d3ad')\n",
        "sp = spotipy.Spotify(auth_manager=auth_manager)"
      ],
      "metadata": {
        "id": "bkH4UG8kN2eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_num = 1   # change the number from whichever chunk you want tomextract features from\n",
        "\n",
        "chunk = pd.read_csv('/content/drive/MyDrive/Datasets/chunk_'+str(chunk_num)+'.csv')\n",
        "chunk.drop(columns='Unnamed: 0',inplace=True)\n",
        "chunk = chunk.values.ravel()\n",
        "Extract_Features(chunk,\"Chunk_\"+str(chunk_num))"
      ],
      "metadata": {
        "id": "CCxLgWZFOD9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}